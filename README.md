# QA-система на основе Agentic RAG для обработки естественно-языковых запросов к структурированным данным

## Постановка задачи

**Разработка комплексного сервиса для обработки естественно-языковых запросов к структурированным данным о резюме, основанного на Agentic RAG, включающего:**

1. **Генерацию резюме на основе параметров пользователя**:

   * Система должна позволять пользователям создавать резюме, генерируя его в ответ на запросы, сформированные в естественном языке. Например, пользователь может задать запрос, как "Создай резюме для программиста с 5 годами опыта работы в Python".

2. **Парсинг резюме из PDF в структурированный формат**:

   * Система должна быть способна извлекать данные из резюме в PDF формате и преобразовывать их в структурированный формат (например, JSON или LaTeX), чтобы предоставить возможность использования этих данных для анализа или генерации новых запросов.

3. **Интеграция Text-to-SQL агента для выполнения аналитических запросов**:

   * Agentic RAG должен быть использован для выполнения сложных аналитических запросов на базе данных резюме. Это может включать запросы вроде "Покажи мне все резюме с опытом работы в области машинного обучения и Python", или "Найди кандидатов, которые работали в компании X в течение более 3 лет".
   * Система должна переводить запросы на естественном языке в SQL-запросы, чтобы извлекать нужную информацию из базы данных.

4. **Web-интерфейс для взаимодействия с пользователем**:

   * Пользователи должны иметь возможность взаимодействовать с системой через веб-интерфейс, задавая вопросы и получая ответы, как на основе данных резюме, так и на основе структурированных данных в базе. Веб-интерфейс должен обеспечивать возможность:

     * Вводить и редактировать резюме.
     * Задавать аналитические запросы на основе данных резюме.
     * Получать ответы на вопросы в виде структурированных данных или графиков.

5. **Интеграция Agentic RAG для обработки запросов**:

   * Система должна использовать **RAG (Retrieval-Augmented Generation)** подход, где для ответа на запросы будет использоваться как доступ к базе данных, так и генеративные способности модели для построения точных и осмысленных ответов на основе имеющихся данных.
   * Система должна эффективно работать с запросами на естественном языке, как с простыми, так и с более сложными, комбинируя данные из базы и возможности генерации.

## Сервис состоит из следующих компонентов

* **resume\_generator** — микросервис генерации резюме (PDF, JSON, LaTeX);
* **resume\_parser** — микросервис парсинга резюме (PDF → JSON/LaTeX);
* **agent** — Text-to-SQL агент, обрабатывающий естественные запросы к БД;
* **streamlit** — клиентская часть (интерфейс пользователя);
* **postgres** — централизованное хранилище структурированных данных о резюме;
* **data\_loader** — модуль начальной загрузки данных;
* **notebooks** — исследовательская часть с экспериментами и разработкой моделей.

Результатом работы является развернутый в контейнерах сервис, позволяющий пользователю:

1. Сгенерировать резюме;
2. Загрузить и распарсить существующее резюме;
3. Задать вопрос на естественном языке (например, "Покажи кандидатов с опытом в ML более 3 лет") и получить SQL-запрос с результатами.

### Стек

#### ⚙️ Backend-инфраструктура

* **FastAPI** (`fastapi>=0.115.12`) — современный фреймворк для построения высокопроизводительных API;
* **Uvicorn** (`uvicorn>=0.34.0`) — ASGI-сервер для запуска FastAPI-приложений;
* **Pydantic v2** (`pydantic>=2.11.2`, `pydantic-settings>=2.8.1`) — декларативная валидация и управление конфигурацией;
* **SQLAlchemy** (опционально, если используется) — ORM для взаимодействия с базой данных;
* **psycopg2-binary** (`>=2.9.10`) — драйвер для подключения к PostgreSQL;
* **sqlparse** (`>=0.5.3`) — парсинг и форматирование SQL-запросов;

#### 🧠 Работа с LLM и агентами

* **OpenAI SDK** (`openai>=1.74.0`) — доступ к API языковых моделей;
* **smolagents** (`smolagents>=1.13.0`) — lightweight-фреймворк для создания LLM-агентов (например, Text-to-SQL агент);
* **pydantic-ai** (`pydantic-ai>=0.1.3`) — обертка для типизированной работы с AI-ответами;

#### 📄 Генерация и парсинг резюме

* **faker** (`faker>=37.1.0`) — генерация фейковых данных (имена, адреса, опыт и т.п.) для создания реалистичных резюме;
* **jinja2** (`jinja2>=3.1.6`) — шаблонизатор для генерации LaTeX;
* **latexbuild** (`latexbuild>=0.2.2`) — сборка PDF из LaTeX-резюме;
* **pymupdf** (`pymupdf>=1.25.5`) — извлечение текста и структуры из PDF-документов;

#### 📊 Обработка и анализ данных

* **pandas** (`pandas>=2.2.3`) — аналитика и структурирование информации в формате таблиц;

#### 🧪 Исследования

* **Jupyter Notebooks** — запуск экспериментов, тестирование моделей и анализ результатов;
* Примеры находятся в директории `notebooks/`.

### Структура проекта

```plaintext
📦project-root
┣📂agent/ ← Text to SQL агент
┃  ┣📜Dockerfile ← Контейнер агента
┃  ┣📜main.py ← Точка входа агента
┃  ┣📂src/ ← Исходный код агента
┃  ┗📜__init__.py
┃
┣📂resume_generator/ ← Генератор резюме
┃  ┣📜Dockerfile ← Контейнер генератора резюме
┃  ┣📜main.py ← Основной скрипт генерации
┃  ┣📂config/ ← Конфигурации генератора
┃  ┣📂src/ ← Логика генерации
┃  ┗📜__init__.py
┃
┣📂resume_parser/ ← Парсер резюме
┃  ┣📜Dockerfile ← Контейнер парсера резюме
┃  ┣📜main.py ← Основной скрипт парсинга
┃  ┣📂config/ ← Конфигурации парсера
┃  ┣📂src/ ← Логика парсинга
┃  ┗📜__init__.py
┃
┣📂streamlit/ ← Веб-интерфейс
┃  ┣📜Dockerfile ← Контейнер Streamlit UI
┃  ┣📜streamlit_app.py ← Основное приложение
┃  ┣📂src/ ← Вспомогательные модули
┃  ┣📂tabs/ ← Вкладки интерфейса
┃  ┣📂assets/ ← Статика (иконки, изображения, стили)
┃  ┗📜__init__.py
┃
┣📂data/ ← Хранилище файлов резюме
┃  ┣📂resumes_pdf/ ← PDF-файлы резюме
┃  ┣📂resumes_json/ ← JSON-представления резюме
┃  ┗📂resumes_latex/ ← LaTeX-файлы, используемые для генерации PDF
┃
┣📂db/ ← PostgreSQL база данных
┃  ┣📜Dockerfile ← Контейнер базы данных
┃  ┣📜init.sql ← Инициализация схемы
┃  ┣📜load_initial_data.py ← Загрузка стартовых данных
┃  ┗📜__init__.py
┃
┣📂notebooks/ ← Jupyter-ноутбуки для анализа и экспериментов
┃  ┣📜db_data_insert.ipynb ← Загрузка данных в БД
┃  ┣📜resume_generation.ipynb ← Генерация резюме
┃  ┣📜resume_parsing_experiments.ipynb ← Эксперименты с парсингом
┃  ┣📜smolagent.ipynb ← Работа с агентом
┃  ┣📜sql_agent_exp_0.ipynb ← SQL-агент, эксперимент 0
┃  ┣📜sql_agent_exp_1.ipynb ← SQL-агент, эксперимент 1
┃  ┗📜sql_agent_exp_bare_python.ipynb ← SQL-агент на чистом Python
┃
┣📜docker-compose.yaml ← Сборка и запуск всех компонентов
┣📜Makefile ← Сценарии запуска проекта
┣📜README.md ← Документация по проекту
┣📜LICENSE ← Лицензия проекта
┣📜pyproject.toml ← Конфигурация зависимостей Python
┗📜uv.lock ← Лок-файл зависимостей (PDM/Poetry/Pipenv)
```

### Развертывание

Проект разворачивается с помощью `docker-compose`, описывающего все зависимости и связи между сервисами. Используется механизм healthcheck для проверки готовности компонентов.

### Запуск проекта

#### Старт сервисов

```bash
make start
```

#### Остановка сервисов

```bash
make stop
```
