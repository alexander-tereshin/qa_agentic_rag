{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "openai._utils._logs.logger.setLevel(logging.WARNING)  # noqa: SLF001\n",
    "openai._utils._logs.httpx_logger.setLevel(logging.WARNING)  # noqa: SLF001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/jeromeblanchet/yale-universitys-spider-10-nlp-dataset\n",
      "License(s): unknown\n",
      "Downloading yale-universitys-spider-10-nlp-dataset.zip to /Users/ruathar/Developer/qa_agentic_rag/data\n",
      "  0%|                                               | 0.00/96.0M [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 96.0M/96.0M [00:00<00:00, 3.66GB/s]\n"
     ]
    }
   ],
   "source": [
    "download_path = Path.cwd() / \"data\"\n",
    "!kaggle datasets download -d jeromeblanchet/yale-universitys-spider-10-nlp-dataset -p \"{download_path}\" --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_path = Path(\"data/spider\")\n",
    "\n",
    "with (spider_path / \"tables.json\").open() as f:\n",
    "    tables = json.load(f)\n",
    "\n",
    "with (spider_path / \"dev.json\").open() as f:\n",
    "    dev_examples = json.load(f)\n",
    "\n",
    "with (spider_path / \"dev_gold.sql\").open() as f:\n",
    "    gold_sql = f.readlines()\n",
    "\n",
    "db_schemas = {table[\"db_id\"]: table for table in tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with something specific.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_api_url = os.getenv(\"LLM_API_URL\")\n",
    "api_key = os.getenv(\"LLM_API_TOKEN\")\n",
    "llm_model = os.getenv(\"LLM_API_MODEL\")\n",
    "client = openai.Client(base_url=llm_api_url, api_key=api_key)\n",
    "\n",
    "\n",
    "client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hi!\",\n",
    "        }\n",
    "    ],\n",
    "    model=llm_model,\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqlQuery(BaseModel):\n",
    "    reasoning: str = Field(..., description=\"Напиши свои мысли, как ты формируешь sql запрос\")\n",
    "    sql_query: str | None\n",
    "\n",
    "\n",
    "def get_db_schema(db_id: str) -> str:\n",
    "    schema = db_schemas[db_id]\n",
    "    table_names = schema[\"table_names_original\"]\n",
    "    column_data = schema[\"column_names_original\"]\n",
    "\n",
    "    table_columns = {table: [] for table in table_names}\n",
    "\n",
    "    for table_idx, col_name in column_data:\n",
    "        if table_idx == -1 or col_name == \"*\":\n",
    "            continue\n",
    "        table_name = table_names[table_idx]\n",
    "        table_columns[table_name].append(col_name)\n",
    "\n",
    "    result_lines = [f\"Схема базы данных: {db_id}\\n\"]\n",
    "    for table, columns in table_columns.items():\n",
    "        result_lines.extend([f\"Таблица: {table}\", \"Столбцы:\", *[f\"- {col}\" for col in columns], \"\"])\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "def generate_sql(db_id: str, question: str, client: openai.Client, model: str) -> str:\n",
    "    full_schema = get_db_schema(db_id)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Ты — AI-ассистент, генерирующий SQL-запросы на основе пользовательских запросов.\\n\"\n",
    "        \"Ниже — схема базы данных:\\n\\n\"\n",
    "        f\"{full_schema}\\n\\n\"\n",
    "        \"1) Проанализируй запрос.\\n\"\n",
    "        \"2) Опиши reasoning.\\n\"\n",
    "        \"3) Cгенерируй корректный SELECT и верни его в поле sql_query.\\n\"\n",
    "        \"4) Оптимизируй запрос для минимальной нагрузки на БД.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Запрос пользователя: {question}\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=0.25,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        response_format=SqlQuery,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed.sql_query\n",
    "\n",
    "\n",
    "def execute_sql(db_id: str, sql: str) -> str | None:\n",
    "    db_path = spider_path / f\"database/{db_id}/{db_id}.sqlite\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "    except Exception:\n",
    "        logger.exception(\"Error executing SQL:\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос:  How many singers do we have?\n",
      "Сгенерированный SQL: SELECT COUNT(DISTINCT Singer_ID) AS NumberOfSingers FROM singer;\n",
      "Эталонный (gold) SQL:  SELECT count(*) FROM singer\n"
     ]
    }
   ],
   "source": [
    "example = dev_examples[0]\n",
    "\n",
    "print(\"Вопрос: \", example[\"question\"])\n",
    "print(\"Сгенерированный SQL:\", generate_sql(example[\"db_id\"], example[\"question\"], client=client, model=llm_model))\n",
    "print(\"Эталонный (gold) SQL: \", gold_sql[0].split(\"\\t\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Accuracy: Correct\n"
     ]
    }
   ],
   "source": [
    "def compare_execution(generated_result: list, gold_result: list) -> bool:\n",
    "    return generated_result == gold_result\n",
    "\n",
    "\n",
    "gold_example = gold_sql[0].strip().split(\"\\t\")\n",
    "gold_sql_query = gold_example[0]\n",
    "gold_db_id = gold_example[1]\n",
    "gold_execution_result = execute_sql(gold_db_id, gold_sql_query)\n",
    "generation_result = generate_sql(example[\"db_id\"], example[\"question\"], client, \"qwen2.5:7b\")\n",
    "execution_result = execute_sql(example[\"db_id\"], generation_result)\n",
    "\n",
    "if gold_execution_result:\n",
    "    print(f\"Execution Accuracy: {'Correct' if compare_execution(execution_result, gold_execution_result) else 'Incorrect'}\")\n",
    "else:\n",
    "    print(\"Error: Unable to execute gold SQL query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_execution_accuracy(\n",
    "        examples: list[dict],\n",
    "        client: openai.Client,\n",
    "        model_name: str,\n",
    "        num_questions: int,\n",
    "        ) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, ex in enumerate(tqdm(examples[:num_questions], desc=\"Evaluating Execution Accuracy\")):\n",
    "        question = ex[\"question\"]\n",
    "        db_id = ex[\"db_id\"]\n",
    "        gold_sql_query = ex[\"query\"]\n",
    "        gold_result = execute_sql(db_id, gold_sql_query)\n",
    "\n",
    "        if isinstance(gold_result, str) and gold_result.startswith(\"Error\"):\n",
    "            logger.warning(f\"[{i}] ⚠️ Ошибка в gold SQL: {gold_result}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            generated_sql = generate_sql(db_id, question, client, model_name)\n",
    "            generated_result = execute_sql(db_id, generated_sql)\n",
    "        except Exception:\n",
    "            logger.exception(f\"[{i}] ❌ Ошибка генерации или выполнения SQL\")\n",
    "            continue\n",
    "\n",
    "        if isinstance(generated_result, str) and generated_result.startswith(\"Error\"):\n",
    "            logger.warning(f\"[{i}] ⚠️ Ошибка выполнения сгенерированного SQL: {generated_result}\")\n",
    "            continue\n",
    "\n",
    "        if compare_execution(generated_result, gold_result):\n",
    "            correct += 1\n",
    "            logger.info(f\"[{i}] ✅ Корректно\")\n",
    "        else:\n",
    "            logger.info(f\"[{i}] ❌ Некорректно\")\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total else 0.0\n",
    "    logger.info(f\"Execution Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_openai_client(model_name: str) -> tuple[openai.Client, str]:\n",
    "    if model_name.startswith(\"gpt\"):\n",
    "        base_url = os.getenv(\"LLM_API_URL_OPENAI\")\n",
    "        api_key = os.getenv(\"LLM_API_TOKEN_OPENAI\")\n",
    "        model = model_name\n",
    "    else:\n",
    "        base_url = os.getenv(\"LLM_API_URL\")\n",
    "        api_key = os.getenv(\"LLM_API_TOKEN\")\n",
    "        model = model_name\n",
    "\n",
    "    client = openai.Client(base_url=base_url, api_key=api_key)\n",
    "    return client, model\n",
    "\n",
    "\n",
    "def benchmark_models_on_spider(models: list[str], examples: list[dict], num_questions: int = 100) -> pd.DataFrame:\n",
    "    results = []\n",
    "\n",
    "    for model_name in models:\n",
    "        try:\n",
    "            client, model_id = get_openai_client(model_name)\n",
    "            acc = evaluate_execution_accuracy(examples, client=client, model_name=model_id, num_questions=num_questions)\n",
    "            results.append({\"model\": model_name, \"execution_accuracy\": acc})\n",
    "        except Exception:\n",
    "            logger.exception(f\"❌ Model {model_name} failed\")\n",
    "            results.append({\"model\": model_name, \"execution_accuracy\": None})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:20,848 [INFO] [0] ✅ Корректно\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "2025-05-15 02:23:20,851 [INFO] Execution Accuracy: 1.0\n",
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:27,934 [INFO] [0] ✅ Корректно\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it]\n",
      "2025-05-15 02:23:27,936 [INFO] Execution Accuracy: 1.0\n",
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:33,420 [INFO] [0] ✅ Корректно\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:05<00:00,  5.48s/it]\n",
      "2025-05-15 02:23:33,422 [INFO] Execution Accuracy: 1.0\n",
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:36,472 [ERROR] [0] ❌ Ошибка генерации или выполнения SQL\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/4285121679.py\", line 21, in evaluate_execution_accuracy\n",
      "    generated_sql = generate_sql(db_id, question, client, model_name)\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/3378380415.py\", line 41, in generate_sql\n",
      "    response = client.beta.chat.completions.parse(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        response_format=SqlQuery,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/resources/beta/chat/completions.py\", line 158, in parse\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream=False,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1034, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "2025-05-15 02:23:36,478 [INFO] Execution Accuracy: 0.0\n",
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:38,556 [ERROR] [0] ❌ Ошибка генерации или выполнения SQL\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 156, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 154, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Authority Key Identifier (_ssl.c:1028)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Authority Key Identifier (_ssl.c:1028)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/4285121679.py\", line 21, in evaluate_execution_accuracy\n",
      "    generated_sql = generate_sql(db_id, question, client, model_name)\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/3378380415.py\", line 41, in generate_sql\n",
      "    response = client.beta.chat.completions.parse(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        response_format=SqlQuery,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/resources/beta/chat/completions.py\", line 158, in parse\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream=False,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1001, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "2025-05-15 02:23:38,569 [INFO] Execution Accuracy: 0.0\n",
      "Evaluating Execution Accuracy:   0%|          | 0/1 [00:00<?, ?it/s]2025-05-15 02:23:40,856 [ERROR] [0] ❌ Ошибка генерации или выполнения SQL\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 156, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 154, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Authority Key Identifier (_ssl.c:1028)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Missing Authority Key Identifier (_ssl.c:1028)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/4285121679.py\", line 21, in evaluate_execution_accuracy\n",
      "    generated_sql = generate_sql(db_id, question, client, model_name)\n",
      "  File \"/var/folders/gn/2rl2yrpd6kd1xyntb037l6s1ymb2cb/T/ipykernel_2296/3378380415.py\", line 41, in generate_sql\n",
      "    response = client.beta.chat.completions.parse(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        response_format=SqlQuery,\n",
      "    )\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/resources/beta/chat/completions.py\", line 158, in parse\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream=False,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ruathar/Developer/qa_agentic_rag/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1001, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Evaluating Execution Accuracy: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "2025-05-15 02:23:40,861 [INFO] Execution Accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>execution_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma3:12b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen2.5-coder:7b</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  execution_accuracy\n",
       "0        qwen2.5:7b                 1.0\n",
       "1        gemma3:12b                 1.0\n",
       "2  qwen2.5-coder:7b                 1.0\n",
       "3     gpt-3.5-turbo                 0.0\n",
       "4             gpt-4                 0.0\n",
       "5            gpt-4o                 0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_to_test = [\"qwen2.5:7b\", \"qwen2.5-coder:7b\", \"gemma3:12b\", \"gpt-4o\", \"gpt-4-mini\"]\n",
    "\n",
    "df_results = benchmark_models_on_spider(models_to_test, dev_examples, num_questions=1)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
