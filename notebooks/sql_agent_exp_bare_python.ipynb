{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from openai import Client\n",
    "from psycopg2.extensions import connection\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "llm_api_url = os.getenv(\"AGENT_LLM_API_URL\")\n",
    "api_key = os.getenv(\"AGENT_LLM_API_TOKEN\")\n",
    "model = os.getenv(\"AGENT_LLM_API_MODEL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(base_url=llm_api_url, api_key=api_key)\n",
    "\n",
    "db_params = {\n",
    "    \"host\": os.environ.get(\"POSTGRES_HOST\", \"127.0.0.1\"),\n",
    "    \"port\": os.environ.get(\"POSTGRES_PORT\", \"5432\"),\n",
    "    \"database\": os.environ.get(\"POSTGRES_DB\", \"your_database\"),\n",
    "    \"user\": os.environ.get(\"POSTGRES_USER\", \"your_username\"),\n",
    "    \"password\": os.environ.get(\"POSTGRES_PASSWORD\", \"your_password\"),\n",
    "}\n",
    "\n",
    "\n",
    "def get_available_tables(schema: str = \"public\") -> list[str]:\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = %s AND table_type = 'BASE TABLE';\n",
    "        \"\"\",\n",
    "        (schema,),\n",
    "    )\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "    conn.close()\n",
    "    logger.debug(f\"Available tables: {tables}\")\n",
    "    return tables\n",
    "\n",
    "\n",
    "def get_table_schema(table_name: str) -> str:\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = %s;\n",
    "        \"\"\",\n",
    "        (table_name,),\n",
    "    )\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    schema = \"\\n\".join(f\"- {col[0]} ({col[1]})\" for col in columns)\n",
    "    logger.debug(f\"Schema for {table_name}:\\n{schema}\")\n",
    "    return schema\n",
    "\n",
    "\n",
    "def get_table_preview(table_name: str, limit: int = 10) -> list[dict]:\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    cursor.execute(f\"SELECT * FROM {table_name} LIMIT {limit}\")  # noqa: S608\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    logger.debug(f\"Preview first {limit} rows from {table_name}: {rows}\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "def sql_engine(query: str) -> str:\n",
    "    \"\"\"Execute validated SQL SELECT queries on the 'resumes' table and returns results as a JSON string.\"\"\"\n",
    "    logger.info(f\"Executing SQL: {query}\")\n",
    "    try:\n",
    "        with psycopg2.connect(**db_params) as conn, conn.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "            cursor.execute(query)\n",
    "            try:\n",
    "                results = cursor.fetchall()\n",
    "            except psycopg2.ProgrammingError:\n",
    "                logger.info(\"Query executed successfully, but no results to fetch.\")\n",
    "                return []\n",
    "            else:\n",
    "                logger.debug(f\"SQL results: {results}\")\n",
    "                return results\n",
    "    except psycopg2.errors.SyntaxError:\n",
    "        logger.exception(\"Syntax error in SQL query\")\n",
    "    except psycopg2.Error:\n",
    "        logger.exception(\"Database error\")\n",
    "    return []\n",
    "\n",
    "\n",
    "class SQLRequest(BaseModel):\n",
    "    reasoning: str = Field(..., description=\"Почему запрос безопасен или опасен\")\n",
    "    is_dangerous: bool = Field(..., description=\"Флаг опасности\")\n",
    "    sql_query: str | None = Field(None, description=\"SQL для выполнения, если safe\")\n",
    "\n",
    "\n",
    "class AgentAction(BaseModel):\n",
    "    function: Literal[\"sql_engine\"]\n",
    "    reasoning: str = Field(..., description=\"Напиши свои мысли, как ты формируешь sql запрос\")\n",
    "    is_dangerous: bool\n",
    "    sql_query: str | None\n",
    "\n",
    "\n",
    "def analyze_user_message(message: str) -> AgentAction:\n",
    "    logger.info(f\"Analyzing user message: {message}\")\n",
    "    tables = get_available_tables()\n",
    "    schema_blocks = [f\"Table `{tbl}`:\\n{get_table_schema(tbl)}\" for tbl in tables]\n",
    "    full_schema = \"\\n\\n\".join(schema_blocks)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Ты — AI-ассистент, генерирующий SQL-запросы на основе пользовательских запросов.\\n\"\n",
    "        \"Ниже — схема базы данных PostgreSQL:\\n\\n\"\n",
    "        f\"{full_schema}\\n\\n\"\n",
    "        \"1) Проанализируй запрос.\\n\"\n",
    "        \"2) Если он опасен или модифицирует данные — установи is_dangerous=true и опиши reasoning.\\n\"\n",
    "        \"3) Если безопасен — сгенерируй корректный SELECT и верни его в поле sql_query.\\n\"\n",
    "        \"4) Перефразируй запрос пользователя как комментарий перед SQL.\\n\"\n",
    "        \"5) Учитывай различные варианты написания специальностей.\\n\"\n",
    "        \"6) Оптимизируй запрос для минимальной нагрузки на БД.\"\n",
    "    )\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=0.5,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}],\n",
    "        response_format=AgentAction,\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content\n",
    "    logger.debug(f\"Raw LLM response: {raw}\")\n",
    "\n",
    "    action: AgentAction = response.choices[0].message.parsed\n",
    "    logger.info(f\"LLM reasoning: {action.reasoning}\")\n",
    "    logger.debug(f\"Parsed AgentAction: {action.model_dump_json()}\")\n",
    "    if action.sql_query:\n",
    "        logger.info(f\"Generated SQL query: {action.sql_query}\")\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sql_result_with_llm(user_message: str, sql_query: str, raw_result: str) -> str:\n",
    "    \"\"\"Форматирует результат SQL-запроса в человекочитаемый ответ с помощью LLM.\"\"\"\n",
    "    system_prompt = (\n",
    "        \"Ты — умный помощник, который объясняет результат SQL-запроса пользователю простыми словами.\\n\"\n",
    "        \"Вот что нужно сделать:\\n\"\n",
    "        \"1) Прочитай исходный пользовательский запрос.\\n\"\n",
    "        \"2) Посмотри, какой SQL был сгенерирован.\\n\"\n",
    "        \"3) Посмотри на результат (JSON).\\n\"\n",
    "        \"4) Построй понятный, краткий и точный ответ для пользователя на русском языке.\\n\"\n",
    "        \"Не добавляй лишней информации, пиши по существу.\\n\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Запрос пользователя:\\n{user_message}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Сгенерированный SQL:\\n{sql_query}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Результат SQL (JSON):\\n{raw_result}\"},\n",
    "    ]\n",
    "\n",
    "    class FinalAnswer(BaseModel):\n",
    "        answer: int\n",
    "\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=0.15,\n",
    "        messages=messages,\n",
    "        # response_format=FinalAnswer\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content.strip()\n",
    "    logger.debug(f\"LLM-formatted answer: {reply}\")\n",
    "    return reply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_message(message: str) -> str:\n",
    "    logger.info(f\"User message received: {message}\")\n",
    "    action = analyze_user_message(message)\n",
    "\n",
    "    if action.is_dangerous:\n",
    "        logger.warning(f\"Dangerous request rejected: {action.reasoning}\")\n",
    "        return f\"Запрос отклонён: {action.reasoning}\"\n",
    "    if action.function == \"sql_engine\" and action.sql_query:\n",
    "        try:\n",
    "            raw_results = sql_engine(action.sql_query)\n",
    "            logger.info(f\"Query executed successfully, returned {len(raw_results)} rows\")\n",
    "        except Exception:\n",
    "            raw_results = \"Ошибка при выполнении SQL\"\n",
    "            logger.exception(\"SQL execution error\")\n",
    "        return format_sql_result_with_llm(\n",
    "            user_message=message,\n",
    "            sql_query=action.sql_query,\n",
    "            raw_result=raw_results,\n",
    "        )\n",
    "    logger.error(\"No valid SQL query generated\")\n",
    "    return \"Ваш запрос не имеет отношения к базе данных.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 02:22:26 [INFO] User message received: кто шарит за аналитику?\n",
      "2025-05-06 02:22:26 [INFO] Analyzing user message: кто шарит за аналитику?\n",
      "2025-05-06 02:22:31 [INFO] HTTP Request: POST https://llm-api.cibaa.raiffeisen.ru/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-06 02:22:31 [INFO] LLM reasoning: Запрос пользователя не является опасным и не модифицирует данные. Он ищет резюме, где указаны навыки или опыт, связанные с аналитикой.\n",
      "2025-05-06 02:22:31 [INFO] Generated SQL query: -- Кто имеет навыки или опыт, связанные с аналитикой?\n",
      "SELECT id, name, title, summary, skills, experience\n",
      "FROM resumes\n",
      "WHERE skills @> ARRAY['аналитик', 'аналитика', 'data analyst', 'data analysis']::text[]\n",
      "OR experience::text ILIKE ANY (ARRAY['%аналитик%', '%аналитика%', '%data analyst%', '%data analysis%'])\n",
      "LIMIT 100;\n",
      "2025-05-06 02:22:31 [INFO] Executing SQL: -- Кто имеет навыки или опыт, связанные с аналитикой?\n",
      "SELECT id, name, title, summary, skills, experience\n",
      "FROM resumes\n",
      "WHERE skills @> ARRAY['аналитик', 'аналитика', 'data analyst', 'data analysis']::text[]\n",
      "OR experience::text ILIKE ANY (ARRAY['%аналитик%', '%аналитика%', '%data analyst%', '%data analysis%'])\n",
      "LIMIT 100;\n",
      "2025-05-06 02:22:31 [INFO] Query executed successfully, returned 46 rows\n",
      "2025-05-06 02:23:13 [INFO] HTTP Request: POST https://llm-api.cibaa.raiffeisen.ru/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдены кандидаты с навыками и опытом, связанными с аналитикой:\n",
      "\n",
      "1. **Николай Еремеевич Наумов** — Data Analyst с 8-летним стажем. Опыт в анализе данных, визуализации и разработке аналитических моделей.\n",
      "2. **Тетерина София Богдановна** — Data Scientist с 14-летним стажем. Специализируется на машинном обучении и обработке данных.\n",
      "3. **Зиновий Фёдорович Рогов** — Chief Data Officer (CDO) с 9-летним стажем. Опыт в управлении данными и разработке стратегий.\n",
      "4. **Щербакова Ольга Натановна** — Head of Data с 13-летним стажем. Специализируется на управлении данными и разработке аналитических решений.\n",
      "5. **Морозова Фаина Геннадиевна** — Quantitative Analyst с 15-летним стажем. Опыт в разработке алгоритмических моделей для финансовых рынков.\n",
      "6. **Вячеслав Феликсович Карпов** — Data Steward с 10-летним стажем. Опыт в управлении данными и обеспечении их качества.\n",
      "7. **Данилов Адам Ярославович** — Head of Data с 6-летним стажем. Специализируется на управлении данными и разработке стратегий.\n",
      "8. **Шестаков Герасим Демидович** — Head of Data с 8-летним стажем. Опыт в управлении данными и разработке аналитических решений.\n",
      "9. **Селезнев Владислав Бориславович** — Chief Data Officer (CDO) с 7-летним стажем. Опыт в управлении данными и разработке стратегий.\n",
      "10. **Любим Владиславович Нестеров** — Head of Data с 12-летним стажем. Опыт в управлении данными и разработке стратегий.\n",
      "\n",
      "Эти кандидаты обладают необходимыми навыками и опытом для работы с аналитикой.\n"
     ]
    }
   ],
   "source": [
    "query = \"кто шарит за аналитику?\"\n",
    "\n",
    "answer = process_user_message(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ООП"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseClient:\n",
    "    def __init__(self) -> None:\n",
    "        self.db_params = {\n",
    "            \"host\": os.environ.get(\"POSTGRES_HOST\", \"127.0.0.1\"),\n",
    "            \"port\": os.environ.get(\"POSTGRES_PORT\", \"5432\"),\n",
    "            \"database\": os.environ.get(\"POSTGRES_DB\", \"your_database\"),\n",
    "            \"user\": os.environ.get(\"POSTGRES_USER\", \"your_username\"),\n",
    "            \"password\": os.environ.get(\"POSTGRES_PASSWORD\", \"your_password\"),\n",
    "        }\n",
    "    def connect(self) -> connection:\n",
    "        return psycopg2.connect(**self.db_params)\n",
    "\n",
    "    def get_tables(self, schema: str = \"public\") -> list[str]:\n",
    "        with self.connect() as conn, conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                    SELECT table_name\n",
    "                    FROM information_schema.tables\n",
    "                    WHERE table_schema = %s\n",
    "                      AND table_type = 'BASE TABLE';\n",
    "                    \"\"\",\n",
    "                (schema,),\n",
    "            )\n",
    "            tables = [row[0] for row in cur.fetchall()]\n",
    "            logger.debug(f\"Available tables: {tables}\")\n",
    "            return tables\n",
    "\n",
    "    def get_schema(self, table_name: str) -> str:\n",
    "        with self.connect() as conn, conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                    SELECT column_name, data_type\n",
    "                    FROM information_schema.columns\n",
    "                    WHERE table_name = %s;\n",
    "                    \"\"\",\n",
    "                (table_name,),\n",
    "            )\n",
    "            cols = cur.fetchall()\n",
    "            schema = \"\\n\".join(f\"- {c[0]} ({c[1]})\" for c in cols)\n",
    "            logger.debug(f\"Schema for {table_name}:\\n{schema}\")\n",
    "            return schema\n",
    "\n",
    "    def execute(self, query: str) -> list[dict]:\n",
    "        logger.info(f\"Executing SQL: {query}\")\n",
    "        with self.connect() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            cur.execute(query)\n",
    "            results = cur.fetchall()\n",
    "            logger.debug(f\"SQL results: {results}\")\n",
    "            return results\n",
    "\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, api_url: str, api_key: str, model: str) -> None:\n",
    "        self.client = Client(base_url=api_url, api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def analyze(self, prompt: str, user_message: str) -> AgentAction:\n",
    "        resp = self.client.beta.chat.completions.parse(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt}, {\"role\": \"user\", \"content\": user_message}],\n",
    "            response_format=AgentAction,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content\n",
    "        logger.debug(f\"Raw LLM response: {raw}\")\n",
    "        action = resp.choices[0].message.parsed\n",
    "        logger.info(f\"LLM reasoning: {action.reasoning}\")\n",
    "        logger.debug(f\"Parsed AgentAction: {action.model_dump_json()}\")\n",
    "        return action\n",
    "\n",
    "\n",
    "class SQLAgent:\n",
    "    def __init__(self, api_url: str, api_key: str, model: str) -> None:\n",
    "        self.db = DatabaseClient()\n",
    "        self.llm = LLMClient(api_url, api_key, model)\n",
    "\n",
    "    def build_prompt(self) -> str:\n",
    "        tables = self.db.get_tables()\n",
    "        schema = \"\\n\\n\".join(f\"Table `{t}`:\\n{self.db.get_schema(t)}\" for t in tables)\n",
    "        return (\n",
    "            \"Ты — AI-ассистент, генерирующий оптимизированные SQL-запросы SELECT на основе пользовательских запросов.\\n\"\n",
    "            \"Ниже — схема базы данных PostgreSQL:\\n\\n\"\n",
    "            f\"{schema}\\n\\n\"\n",
    "            \"Правила распознавания ролей и специальностей:\\n\"\n",
    "            \"- Вычленяй любые профессии/роли из запроса (devops, frontend, backend и др.) и нормализуй их.\\n\"\n",
    "            \"- Учитывай вариации написания: регистр, пробелы, дефисы, транслитерацию.\\n\\n\"\n",
    "            \"Правила генерации ответа:\\n\"\n",
    "            \"1) Безопасность: если опасно — is_dangerous=true и объяснение.\\n\"\n",
    "            \"2) Если safe — сгенерируй оптимальный SELECT с учётом индексов.\\n\"\n",
    "            \"3) Перефразируй запрос как комментарий перед SQL.\\n\"\n",
    "            \"4) Минимизируй нагрузку: только необходимые поля, без лишних JOIN.\\n\"\n",
    "        )\n",
    "\n",
    "    def handle(self, user_message: str) -> None | str:\n",
    "        prompt = self.build_prompt()\n",
    "        action = self.llm.analyze(prompt, user_message)\n",
    "        if action.is_dangerous:\n",
    "            return f\"Запрос отклонён: {action.reasoning}\"\n",
    "        if action.sql_query:\n",
    "            return self.db.execute(action.sql_query)\n",
    "        return \"Не удалось сформировать SQL-запрос.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 01:44:32 [INFO] HTTP Request: POST https://llm-api.cibaa.raiffeisen.ru/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-06 01:44:32 [INFO] LLM reasoning: Пользователь хочет узнать, сколько резюме содержат навык 'Python'.\n",
      "2025-05-06 01:44:32 [INFO] Executing SQL: -- Сколько резюме содержат навык 'Python'\n",
      "SELECT COUNT(*)\n",
      "FROM resumes\n",
      "WHERE 'Python' = ANY (skills);\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RealDictRow([('count', 111)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = SQLAgent(llm_api_url, api_key, model)\n",
    "query = \"сколько умеет в питон?\"\n",
    "agent.handle(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
